<h3> 顔認識テスト </h3>

<div class="container">
  <div class="row">
    <div class="col-md-7">
      <div id="sample"></div><br /><br />
      <button class="btn btn-primary" id="start">
        <i class="fa fa-play" aria-hidden="true"></i>
      </button>
      <button class="btn btn-primary" id="pause">
        <i class="fa fa-pause" aria-hidden="true"></i>
      </button>
      <button class="btn btn-primary" id="now">
        <i class="fa fa-clock-o" aria-hidden="true"></i>
      </button>
      <br /><br />
      <%= form_for("gaze", :method => :post, :remote => true, html: {:id => "send"}) do |f| %>
        <%= f.hidden_field :gaze, :value => "" %>
        <%= button_tag(type: "submit", class: "btn btn-primary", name: "output", id: "output") do %> Output <% end %>
      <% end %>
      <!--
      <div class="youtube-container">
        <iframe id="player" type="text/html" width="600" height="350"
        src="https://www.youtube.com/embed/MdQGUFSM8w4"
        frameborder="0">
        </iframe>
      </div>
      -->
    </div>
  <div class="col-md-5">
    <pre class="console">
      <div class="string">
        <div id="time"></div>
      </div>
    </pre>
  </div>
  <div class="row">
    <div class="col-md-12">
      <!--
      <video id="video" width="600" height="350">
        <%= video_tag("video1.mp4", :autoplay => true, :autobuffer => true, :controls => true) %>
      </video>
    -->
    <br /><br />
    </div>
  </div>
  <div class="row">
    <div class="col-md-6">
      <div id="video">
        <video id="target" width="400" height="300" autoplay loop></video>
        <canvas id="result" width="400" height="300"></canvas>
      </div>
    </div>
    <div class="col-md-3">
      <div id="pos">
        <p id="positions">positions<br/></p>
      </div>
    </div>
    <div class="col-md-3">
      <div id="emo">
        <p id="emotes" style ="font-size: 24pt">emotes<br/></p>
      </div>
    </div>
  </div>
</div>

<script src="assets/clmtrackr.js"></script>
<script src="assets/model_pca_20_svm_emotion.js"></script>
<script src="assets/emotionClassifier.js"></script>
<script src="assets/emotionModel.js"></script>
<script src="https://www.youtube.com/iframe_api"></script>
<script type="text/javascript">

// YouTube Player APIを読み込む
var tag = document.createElement('script');
tag.src = "https://www.youtube.com/iframe_api";
var firstScriptTag = document.getElementsByTagName('script')[0];
firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

var ytPlayer;
var ytArea = 'sample';
//var ytID = 'MdQGUFSM8w4';
var ytID = '48n9x3NYZtE';

// API読み込み後にプレーヤー埋め込み
function onYouTubeIframeAPIReady() {
  ytPlayer = new YT.Player(ytArea, {
    width: 600,
    height: 350,
    videoId: ytID
  });
}

// 動画再生
document.getElementById('start').addEventListener('click', function() {
    ytPlayer.loadVideoById(ytID);
}, false);

// 動画一時停止
document.getElementById('pause').addEventListener('click', function() {
    ytPlayer.pauseVideo();
}, false);

// 現在の再生時間
document.getElementById('now').addEventListener('click', function() {
    $("#time").append(ytPlayer.getCurrentTime()).append('<br />');
}, false);

// 視線情報の出力
//document.getElementById('output').addEventListener('click', function() {
//}, {once: true});

window.addEventListener("load", () => {
  let deviceNavigator = navigator.mediaDevices.getUserMedia({ audio: false, video: true });
  deviceNavigator.then((s) => {
    let target = document.getElementById("target");

    let ctracker = new clm.tracker();
    //target.src = window.URL.createObjectURL(s); // 廃止されたため下のコードに書き換え
    target.srcObject = s;
    ctracker.init(pModel);
    ctracker.start(target);

    let classifier = new emotionClassifier();
    classifier.init(emotionModel);

    let duration = parseInt(ytPlayer.getDuration());
    let cnt = Array.apply(null, Array(duration)).map(function() {return 0});

    let result = document.getElementById("result");
    let context = result.getContext("2d");
    let update = () => { // drawloop
      requestAnimationFrame(update);
      context.clearRect(0, 0, result.width, result.height);
      ctracker.draw(result);
    };
    update();

    let drawLoop = () => {
      requestAnimationFrame(drawLoop);
      var positions = ctracker.getCurrentPosition();
      let emo_params = ctracker.getCurrentParameters();
      let emotion = classifier.meanPredict(emo_params);

      showPosition(positions);
      showEmotionData(emotion);
    };
    drawLoop();

    function showPosition(positions) {
      let positionString = "";
      if (positions) {
        for (var p = 0; p < 10; p++) {
          positionString += "featurepoint "+p+" : ["+positions[p][0].toFixed(2)+","+positions[p][1].toFixed(2)+"]<br/>";
        }
        //console.log(positionString);
        document.getElementById('positions').innerHTML = positionString;
        let playerstate = ytPlayer.getPlayerState();
        if (playerstate == 1 || playerstate == 2) { // 再生中 or 一時停止中
          cnt[parseInt(ytPlayer.getCurrentTime())] += 1;
          document.getElementById('time').innerHTML = cnt;
          document.getElementById('gaze_gaze').value = cnt;
        }
      } else {
        document.getElementById('positions').innerHTML = "false";
      }
    };

    function showEmotionData(emo) {
      let emotionString = "";
      for (var i = 0; i < emo.length; i++) {
        emotionString += emo[i].emotion + ": " + emo[i].value.toFixed(1) + "<br />";
      }
      document.getElementById("emotes").innerHTML = emotionString;
    };
  });
});

</script>
